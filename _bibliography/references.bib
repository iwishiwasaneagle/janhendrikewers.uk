@article{ewers_optimal_2023,
  title = {Optimal Path Planning Using Psychological Profiling in Drone-assisted Missing Person Search},
  author = {Ewers, Jan-Hendrik and Anderson, David and Thomson, Douglas},
  year = {2023},
  month = sep,
  journal = {Advanced Control for Applications},
  pages = {e167},
  issn = {2578-0727, 2578-0727},
  doi = {10.1002/adc2.167},
  urldate = {2023-09-25},
  abstract = {Search and rescue operations are all time-sensitive and this is especially true when searching for a vulnerable missing person, such as a child or elderly person suffering dementia. Recently, Police Scotland Air Support Unit have begun the deployment of drones to assist in missing person search with success, although the efficacy of the search relies upon the expertise of the drone operator. In this paper, several algorithms for planning the search path are compared to determine which approach has the highest probability of finding the missing person in the shortest time. In addition to this, the use of {\textbackslash}'a priori psychological profile information of the subject to create a probability map of likely locations within the search area was explored. This map is then used within a non-linear optimisation to determine the optimal flight path for a given search area and subject profile. Two optimisation solvers were compared; genetic algorithms, particle swarm optimisation. Finally, the most effective algorithm was used to create a coverage path for a real-life location, for which Police Scotland Air Support Unit completed multiple test flights. The generated flight paths based on the predicted intent of the lost person were found to perform statistically better than those of the expert police operators.},
  copyright = {All rights reserved},
  langid = {english},
  oa = {true}
}

@inproceedings{ewers_gis_2023,
  title = {{{GIS Data Driven Probability Map Generation}} for {{Search}} and {{Rescue Using Agents}}},
  booktitle = {{{IFAC World Congress}} 2023},
  author = {Ewers, Jan-Hendrik and Anderson, David and Thomson, Douglas},
  year = {2023},
  pages = {1466--1471},
  doi = {10.1016/j.ifacol.2023.10.1834},
  urldate = {2023-11-23},
  abstract = {Predicting the final resting location of a missing person is critical for search and rescue operations with limited resources. To improve the accuracy and speed of these predictions, simulated agents can be created to replicate the behavior of the missing person. In this paper, we introduce an agent-based model, to simulate various psychological profiles, that move over a physical landscape incorporating real-world data in their decision-making without relying on per-location training. The resultant probability density map of the missing person's location was the result of a combination of Monte Carlo simulations and mobility-time-based sampling. General trends in the data were comparable to historical data sets available. This work presents a flexible agent that can be employed by search and rescue that easily extends to various locations.},
  copyright = {All rights reserved},
  langid = {english},
  oa = {true}
}

@misc{swinton_novel_2024,
  title = {A {{Novel Methodology}} for {{Autonomous Planetary Exploration Using Multi-Robot Teams}}},
  author = {Swinton, Sarah and Ewers, Jan-Hendrik and McGookin, Euan and Anderson, David and Thomson, Douglas},
  year = {2024},
  month = may,
  number = {arXiv:2405.12790},
  eprint = {2405.12790},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.12790},
  urldate = {2024-05-22},
  abstract = {One of the fundamental limiting factors in planetary exploration is the autonomous capabilities of planetary exploration rovers. This study proposes a novel methodology for trustworthy autonomous multi-robot teams which incorporates data from multiple sources (HiRISE orbiter imaging, probability distribution maps, and on-board rover sensors) to find efficient exploration routes in Jezero crater. A map is generated, consisting of a 3D terrain model, traversability analysis, and probability distribution map of points of scientific interest. A three-stage mission planner generates an efficient route, which maximises the accumulated probability of identifying points of interest. A 4D RRT* algorithm is used to determine smooth, flat paths, and prioritised planning is used to coordinate a safe set of paths. The above methodology is shown to coordinate safe and efficient rover paths, which ensure the rovers remain within their nominal pitch and roll limits throughout operation.},
  archiveprefix = {arXiv},
  copyright = {All rights reserved},
  keywords = {Computer Science - Robotics}
}

@inproceedings{ewers_enhancing_2024,
  title = {Enhancing {{Reinforcement Learning}} in {{Sensor Fusion}}: {{A Comparative Analysis}} of {{Cubature}} and {{Sampling-based Integration Methods}} for {{Rover Search Planning}}},
  shorttitle = {Enhancing {{Reinforcement Learning}} in {{Sensor Fusion}}},
  booktitle = {2024 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Ewers, Jan-Hendrik and Swinton, Sarah and Anderson, David and McGookin, Euan and Thomson, Douglas},
  year = {2024},
  month = oct,
  pages = {7825--7830},
  publisher = {IEEE},
  address = {Abu Dhabi, United Arab Emirates},
  doi = {10.1109/IROS58592.2024.10801978},
  urldate = {2025-01-23},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {979-8-3503-7770-5}
}

@misc{ewers_predictive_2024,
  title = {Predictive {{Probability Density Mapping}} for {{Search}} and {{Rescue Using An Agent-Based Approach}} with {{Sparse Data}}},
  author = {Ewers, Jan-Hendrik and Anderson, David and Thomson, Douglas},
  year = {2024},
  number = {arXiv:2412.13317},
  eprint = {2412.13317},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.13317},
  urldate = {2025-01-23},
  abstract = {Predicting the location where a lost person could be found is crucial for search and rescue operations with limited resources. To improve the precision and efficiency of these predictions, simulated agents can be created to emulate the behavior of the lost person. Within this study, we introduce an innovative agent-based model designed to replicate diverse psychological profiles of lost persons, allowing these agents to navigate real-world landscapes while making decisions autonomously without the need for location-specific training. The probability distribution map depicting the potential location of the lost person emerges through a combination of Monte Carlo simulations and mobility-time-based sampling. Validation of the model is achieved using real-world Search and Rescue data to train a Gaussian Process model. This allows generalization of the data to sample initial starting points for the agents during validation. Comparative analysis with historical data showcases promising outcomes relative to alternative methods. This work introduces a flexible agent that can be employed in search and rescue operations, offering adaptability across various geographical locations.},
  archiveprefix = {arXiv},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,Systems and Control (eess.SY)}
}

@article{ewers_deep_2025,
  title = {Deep Reinforcement Learning for Time-Critical Wilderness Search and Rescue Using Drones},
  author = {Ewers, Jan-Hendrik and Anderson, David and Thomson, Douglas},
  year = {2025},
  month = feb,
  journal = {Frontiers in Robotics and AI},
  volume = {11},
  pages = {1527095},
  issn = {2296-9144},
  doi = {10.3389/frobt.2024.1527095},
  urldate = {2025-02-04},
  abstract = {Traditional search and rescue methods in wilderness areas can be time-consuming and have limited coverage. Drones offer a faster and more flexible solution, but optimizing their search paths is crucial for effective operations. This paper proposes a novel algorithm using deep reinforcement learning to create efficient search paths for drones in wilderness environments. Our approach leverages               a priori               data about the search area and the missing person in the form of a probability distribution map. This allows the policy to learn optimal flight paths that maximize the probability of finding the missing person quickly. Experimental results show that our method achieves a significant improvement in search times compared to traditional coverage planning and search planning algorithms by over                                                                        160                     \%                                                                  , a difference that can mean life or death in real-world search operations Additionally, unlike previous work, our approach incorporates a continuous action space enabled by cubature, allowing for more nuanced flight patterns.},
  copyright = {All rights reserved}
}

@misc{ewers_multitarget_2025,
  title = {Multi-{{Target Radar Search}} and {{Track Using Sequence-Capable Deep Reinforcement Learning}}},
  author = {Ewers, Jan-Hendrik and Cormack, David and Gibbs, Joe and Anderson, David},
  year = {2025},
  month = feb,
  number = {arXiv:2502.13584},
  eprint = {2502.13584},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.13584},
  urldate = {2025-02-20},
  abstract = {The research addresses sensor task management for radar systems, focusing on efficiently searching and tracking multiple targets using reinforcement learning. The approach develops a 3D simulation environment with an active electronically scanned array radar, using a multi-target tracking algorithm to improve observation data quality. Three neural network architectures were compared including an approach using fated recurrent units with multi-headed self-attention. Two pre-training techniques were applied: behavior cloning to approximate a random search strategy and an auto-encoder to pre-train the feature extractor. Experimental results revealed that search performance was relatively consistent across most methods. The real challenge emerged in simultaneously searching and tracking targets. The multi-headed self-attention architecture demonstrated the most promising results, highlighting the potential of sequence-capable architectures in handling dynamic tracking scenarios. The key contribution lies in demonstrating how reinforcement learning can optimize sensor management, potentially improving radar systems' ability to identify and track multiple targets in complex environments.},
  archiveprefix = {arXiv},
  copyright = {All rights reserved},
  keywords = {Computer Science - Machine Learning,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control}
}

@misc{ewers_recurrent_2025,
  title = {Recurrent {{Auto-Encoders}} for {{Enhanced Deep Reinforcement Learning}} in {{Wilderness Search}} and {{Rescue Planning}}},
  author = {Ewers, Jan-Hendrik and Anderson, David and Thomson, Douglas},
  year = {2025},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2502.19356},
  urldate = {2025-03-03},
  abstract = {Wilderness search and rescue operations are often carried out over vast landscapes. The search efforts, however, must be undertaken in minimum time to maximize the chance of survival of the victim. Whilst the advent of cheap multicopters in recent years has changed the way search operations are handled, it has not solved the challenges of the massive areas at hand. The problem therefore is not one of complete coverage, but one of maximizing the information gathered in the limited time available. In this work we propose that a combination of a recurrent autoencoder and deep reinforcement learning is a more efficient solution to the search problem than previous pure deep reinforcement learning or optimisation approaches. The autoencoder training paradigm efficiently maximizes the information throughput of the encoder into its latent space representation which deep reinforcement learning is primed to leverage. Without the overhead of independently solving the problem that the recurrent autoencoder is designed for, it is more efficient in learning the control task. We further implement three additional architectures for a comprehensive comparison of the main proposed architecture. Similarly, we apply both soft actor-critic and proximal policy optimisation to provide an insight into the performance of both in a highly non-linear and complex application with a large observation Results show that the proposed architecture is vastly superior to the benchmarks, with soft actor-critic achieving the best performance. This model further outperformed work from the literature whilst having below a fifth of the total learnable parameters and training in a quarter of the time.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,Machine Learning (cs.LG),Systems and Control (eess.SY)}
}

@misc{ewers_stone_2025,
  title = {Stone {{Soup Multi-Target Tracking Feature Extraction For Autonomous Search And Track In Deep Reinforcement Learning Environment}}},
  author = {Ewers, Jan-Hendrik and Gibbs, Joe and Anderson, David},
  year = {2025},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2503.01293},
  urldate = {2025-03-04},
  abstract = {Management of sensing resources is a non-trivial problem for future military air assets with future systems deploying heterogeneous sensors to generate information of the battlespace. Machine learning techniques including deep reinforcement learning (DRL) have been identified as promising approaches, but require high-fidelity training environments and feature extractors to generate information for the agent. This paper presents a deep reinforcement learning training approach, utilising the Stone Soup tracking framework as a feature extractor to train an agent for a sensor management task. A general framework for embedding Stone Soup tracker components within a Gymnasium environment is presented, enabling fast and configurable tracker deployments for RL training using Stable Baselines3. The approach is demonstrated in a sensor management task where an agent is trained to search and track a region of airspace utilising track lists generated from Stone Soup trackers. A sample implementation using three neural network architectures in a search-and-track scenario demonstrates the approach and shows that RL agents can outperform simple sensor search and track policies when trained within the Gymnasium and Stone Soup environment.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,Machine Learning (cs.LG),Robotics (cs.RO),Systems and Control (eess.SY)}
}
