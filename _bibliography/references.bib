@article{ewers_optimal_2023,
  title = {Optimal Path Planning Using Psychological Profiling in Drone-assisted Missing Person Search},
  author = {Ewers, Jan-Hendrik and Anderson, David and Thomson, Douglas},
  year = 2023,
  month = sep,
  journal = {Advanced Control for Applications},
  pages = {e167},
  issn = {2578-0727, 2578-0727},
  doi = {10.1002/adc2.167},
  urldate = {2023-09-25},
  abstract = {Search and rescue operations are all time-sensitive and this is especially true when searching for a vulnerable missing person, such as a child or elderly person suffering dementia. Recently, Police Scotland Air Support Unit have begun the deployment of drones to assist in missing person search with success, although the efficacy of the search relies upon the expertise of the drone operator. In this paper, several algorithms for planning the search path are compared to determine which approach has the highest probability of finding the missing person in the shortest time. In addition to this, the use of \textbackslash 'a priori psychological profile information of the subject to create a probability map of likely locations within the search area was explored. This map is then used within a non-linear optimisation to determine the optimal flight path for a given search area and subject profile. Two optimisation solvers were compared; genetic algorithms, particle swarm optimisation. Finally, the most effective algorithm was used to create a coverage path for a real-life location, for which Police Scotland Air Support Unit completed multiple test flights. The generated flight paths based on the predicted intent of the lost person were found to perform statistically better than those of the expert police operators.},
  copyright = {All rights reserved},
  langid = {english},
  oa = {true}
}

@inproceedings{ewers_gis_2023,
  title = {{{GIS Data Driven Probability Map Generation}} for {{Search}} and {{Rescue Using Agents}}},
  booktitle = {{{IFAC World Congress}} 2023},
  author = {Ewers, Jan-Hendrik and Anderson, David and Thomson, Douglas},
  year = 2023,
  pages = {1466--1471},
  doi = {10.1016/j.ifacol.2023.10.1834},
  urldate = {2023-11-23},
  abstract = {Predicting the final resting location of a missing person is critical for search and rescue operations with limited resources. To improve the accuracy and speed of these predictions, simulated agents can be created to replicate the behavior of the missing person. In this paper, we introduce an agent-based model, to simulate various psychological profiles, that move over a physical landscape incorporating real-world data in their decision-making without relying on per-location training. The resultant probability density map of the missing person's location was the result of a combination of Monte Carlo simulations and mobility-time-based sampling. General trends in the data were comparable to historical data sets available. This work presents a flexible agent that can be employed by search and rescue that easily extends to various locations.},
  copyright = {All rights reserved},
  langid = {english},
  oa = {true}
}

@inproceedings{ewers_enhancing_2024,
  title = {Enhancing {{Reinforcement Learning}} in {{Sensor Fusion}}: {{A Comparative Analysis}} of {{Cubature}} and {{Sampling-based Integration Methods}} for {{Rover Search Planning}}},
  shorttitle = {Enhancing {{Reinforcement Learning}} in {{Sensor Fusion}}},
  booktitle = {2024 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Ewers, Jan-Hendrik and Swinton, Sarah and Anderson, David and McGookin, Euan and Thomson, Douglas},
  year = 2024,
  month = oct,
  pages = {7825--7830},
  publisher = {IEEE},
  address = {Abu Dhabi, United Arab Emirates},
  doi = {10.1109/IROS58592.2024.10801978},
  urldate = {2025-01-23},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {979-8-3503-7770-5}
}

@article{ewers_deep_2025,
  title = {Deep Reinforcement Learning for Time-Critical Wilderness Search and Rescue Using Drones},
  author = {Ewers, Jan-Hendrik and Anderson, David and Thomson, Douglas},
  year = 2025,
  month = feb,
  journal = {Frontiers in Robotics and AI},
  volume = {11},
  pages = {1527095},
  issn = {2296-9144},
  doi = {10.3389/frobt.2024.1527095},
  urldate = {2025-02-04},
  abstract = {Traditional search and rescue methods in wilderness areas can be time-consuming and have limited coverage. Drones offer a faster and more flexible solution, but optimizing their search paths is crucial for effective operations. This paper proposes a novel algorithm using deep reinforcement learning to create efficient search paths for drones in wilderness environments. Our approach leverages               a priori               data about the search area and the missing person in the form of a probability distribution map. This allows the policy to learn optimal flight paths that maximize the probability of finding the missing person quickly. Experimental results show that our method achieves a significant improvement in search times compared to traditional coverage planning and search planning algorithms by over                                                                        160                     \%                                                                  , a difference that can mean life or death in real-world search operations Additionally, unlike previous work, our approach incorporates a continuous action space enabled by cubature, allowing for more nuanced flight patterns.},
  copyright = {All rights reserved}
}

@misc{ewers_multitarget_2025,
  title = {Multi-{{Target Radar Search}} and {{Track Using Sequence-Capable Deep Reinforcement Learning}}},
  author = {Ewers, Jan-Hendrik and Cormack, David and Gibbs, Joe and Anderson, David},
  year = 2025,
  month = feb,
  number = {arXiv:2502.13584},
  eprint = {2502.13584},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.13584},
  urldate = {2025-02-20},
  abstract = {The research addresses sensor task management for radar systems, focusing on efficiently searching and tracking multiple targets using reinforcement learning. The approach develops a 3D simulation environment with an active electronically scanned array radar, using a multi-target tracking algorithm to improve observation data quality. Three neural network architectures were compared including an approach using fated recurrent units with multi-headed self-attention. Two pre-training techniques were applied: behavior cloning to approximate a random search strategy and an auto-encoder to pre-train the feature extractor. Experimental results revealed that search performance was relatively consistent across most methods. The real challenge emerged in simultaneously searching and tracking targets. The multi-headed self-attention architecture demonstrated the most promising results, highlighting the potential of sequence-capable architectures in handling dynamic tracking scenarios. The key contribution lies in demonstrating how reinforcement learning can optimize sensor management, potentially improving radar systems' ability to identify and track multiple targets in complex environments.},
  archiveprefix = {arXiv},
  copyright = {All rights reserved},
  keywords = {Computer Science - Machine Learning,Computer Science - Systems and Control,Electrical Engineering and Systems Science - Systems and Control}
}

@misc{ewers_recurrent_2025,
  title = {Recurrent {{Auto-Encoders}} for {{Enhanced Deep Reinforcement Learning}} in {{Wilderness Search}} and {{Rescue Planning}}},
  author = {Ewers, Jan-Hendrik and Anderson, David and Thomson, Douglas},
  year = 2025,
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2502.19356},
  urldate = {2025-03-03},
  abstract = {Wilderness search and rescue operations are often carried out over vast landscapes. The search efforts, however, must be undertaken in minimum time to maximize the chance of survival of the victim. Whilst the advent of cheap multicopters in recent years has changed the way search operations are handled, it has not solved the challenges of the massive areas at hand. The problem therefore is not one of complete coverage, but one of maximizing the information gathered in the limited time available. In this work we propose that a combination of a recurrent autoencoder and deep reinforcement learning is a more efficient solution to the search problem than previous pure deep reinforcement learning or optimisation approaches. The autoencoder training paradigm efficiently maximizes the information throughput of the encoder into its latent space representation which deep reinforcement learning is primed to leverage. Without the overhead of independently solving the problem that the recurrent autoencoder is designed for, it is more efficient in learning the control task. We further implement three additional architectures for a comprehensive comparison of the main proposed architecture. Similarly, we apply both soft actor-critic and proximal policy optimisation to provide an insight into the performance of both in a highly non-linear and complex application with a large observation Results show that the proposed architecture is vastly superior to the benchmarks, with soft actor-critic achieving the best performance. This model further outperformed work from the literature whilst having below a fifth of the total learnable parameters and training in a quarter of the time.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,FOS: Electrical engineering electronic engineering information engineering,Machine Learning (cs.LG),Systems and Control (eess.SY)}
}

@article{swinton_autonomous_2025,
  title = {Autonomous Mission Planning for Planetary Surface Exploration Using a Team of Micro Rovers},
  author = {Swinton, Sarah and Ewers, Jan-Hendrik and McGookin, Euan and Anderson, David and Thomson, Douglas},
  year = 2025,
  journal = {Frontiers in Robotics and AI},
  volume = {12},
  issn = {2296-9144},
  doi = {10.3389/frobt.2025.1565173}
}

@article{ewers_predictive_2025,
  title = {Predictive {{Probability Density Mapping}} for {{Search}} and {{Rescue Using}} an {{Agent-Based Approach With Sparse Data}}},
  author = {Ewers, Jan-Hendrik and Anderson, David and Thomson, Douglas},
  year = 2025,
  journal = {IEEE Access},
  volume = {13},
  pages = {60802--60813},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2025.3557693},
  urldate = {2025-04-11},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode}
}

@inproceedings{ewers_stone_2025a,
  title = {Stone {{Soup Multi-Target Tracking Feature Extraction}} for {{Autonomous Search}} and {{Track}} in {{Deep Reinforcement Learning Environment}}},
  booktitle = {2025 28th {{International Conference}} on {{Information Fusion}} ({{FUSION}})},
  author = {Ewers, Jan-Hendrik and Gibbs, Joe and Anderson, David},
  year = 2025,
  month = jul,
  pages = {1--8},
  publisher = {IEEE},
  address = {Rio de Janeiro, Brazil},
  doi = {10.23919/FUSION65864.2025.11123969},
  urldate = {2026-01-22},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {978-1-0370-5623-9}
}
